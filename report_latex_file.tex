\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{float}
\usepackage{tabularx}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Predicting MLB Outcomes to Inform Sports Betting\\
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Tony Gonzalez}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\
Pomona, California \\
tonygonzalez@cpp.edu}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Omar Jaber}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\
Pomona, California \\
ojaber@cpp.edu}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Michelle Reyes}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\
Pomona, California \\
mreyes3@cpp.edu}
\and
\IEEEauthorblockN{4\textsuperscript{th} Thomas Tejedor}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\     Pomona, California \\
ttejedor@cpp.edu}
\and
\IEEEauthorblockN{5\textsuperscript{th} Milosz Kryzia}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\
Pomona, California \\
mkryzia@cpp.edu}
\and
\IEEEauthorblockN{6\textsuperscript{th} Aliuddin Khaja}
\IEEEauthorblockA{\textit{Cal Poly Pomona} \\
\textit{CS4210 - Machine Learning}\\
Pomona, California \\
aokhaja@cpp.edu}
}

\maketitle

\begin{abstract}
This project focuses on predicting the hitting outcomes of Shohei Ohtani using machine learning techniques applied to pitch-level MLB Statcast data. By leveraging detailed statistics from the 2024 season—such as pitch type, velocity, location, and game context—we trained three models: a Random Forest 6-class classifier, a Random Forest binary classifier, and a Neural Network binary classifier. Features were engineered using one-hot and label encoding, and all models were evaluated using 5-fold cross-validation. Results show that the neural network achieved the highest AUC (0.72) and best recall for base-reaching outcomes, while the binary Random Forest model achieved the highest overall accuracy (70%).
\end{abstract}

\vspace{10pt}

\begin{IEEEkeywords}
machine learning, sports analytics, sports betting, baseball, classification, predictive modeling, MLB
\end{IEEEkeywords}

\section{Introduction}
This project focuses on predicting the hitting outcomes of Shohei Ohtani using machine learning techniques applied to pitch-level MLB Statcast data. By analyzing detailed information such as pitch type, velocity, location, and batted ball metrics, we aim to estimate the likelihood of Ohtani reaching base during a given plate appearance. The dataset consists of individual pitch events from the 2024 season, allowing us to engineer features that reflect in-game context and pitcher-batter interactions. We train classification models to predict both specific outcomes (e.g., single, strikeout) and binary success indicators (on-base vs. out), with the goal of supporting applications in sports analytics and betting.

\section{Dataset}
The project uses an API from Pybaseball, a Python library that provides Major League Baseball statistics, to gather our dataset. We created three different machine learning models: a Binary neural network model, a Binary Random Forest Classifier and a Multi-class Random Forest Classifier. 

The data set for the neural network model consisted of the following features: 'pitcher', 'release\_speed', 'release\_pos\_x', 'release\_pos\_y', 'zone', 'balls', 'strikes', 'outs\_when\_up', 'inning' and the total values of 'pitch\_name' and 'opponent\_team' derived from one-hot encoding. This resulted in 828 instances and 49 features fed into the model.

Although both Random Forest Classifier used the same features, we reduced the number of features by applying the label encoding technique to two columns, 'pitch\_name' and 'opponent\_team.' This resulted in 828 instances and 11 features fed into the models.

The class distribution differed between the binary classification models and the Random Forest model.
\subsection{Class Distribution}
The class distribution of the binary classification models is 
\begin{itemize}
    \item Class 0: 62.43\%
    \item Class 1: 37.56\%
\end{itemize}

The class distribution of the Random Forest Classifier is

\begin{itemize}
    \item Class 0: 62.43\%
    \item Class 1: 13.89\%
    \item Class 2: 4.83\%
    \item Class 3: 0.97\%
    \item Class 4: 7.00\%
    \item Class 5: 10.87\%
\end{itemize}


\section{Methodology}
For this research, we utilized the PyBaseBall library to gather and easily aggregate information on Shohei Ohtani and the pitchers he played against. When training the model, the features used for inputs include: 'pitcher', 'pitch\_name', 'release\_speed', 'release\_pos\_x', 'release\_pos\_y', 'zone', 'balls', 'strikes', 'outs\_when\_up', 'inning', and 'opponent\_team.' In terms of the target we aimed for, this project aimed to try and predict either which type of hit Shohei would make, or whether he would hit the ball or not. 

For data pre-processing, we removed a number of irrelevant features from the dataset. For the binary models, we set the target variable to be 1 if there was a hit, and 0 if otherwise. For multi class models, we used the event names: 'single', 'double', 'triple', 'home\_run', and 'walk' for the hits. 

One-hot Encoding was used for 'pitch\_name' and 'opponent\_team' since they were nominal features that the model wouldn't be able to learn from. Any missing numerical values were handled by imputation with the mean of those features. StandardScaler() is used on both train and test data.

Both the multiclass and binary RandomForestClassifiers used 100 estimators and enabled balancing to account for imbalanced data. The models were trained with a 80/20 split in data.

The neural network consists of a 64 node ReLU activated dense layer with a kernel regularizer, and Dropout, followed by a 32 node ReLU activated dense layer with the same kernel regularizer and Dropout. It's all then sent through a Sigmoid layer to give a binary output. The model is then trained for 100 Epochs with a batch size of 32, and utilizes Early Stopping to prevent unnecessary training.

The metrics given as results were the precision, recall, f1-score, and support. 

\section{Results}

We evaluated three models to predict Shohei Ohtani’s plate appearance outcomes using pitch-level data from the 2024 MLB season: a Random Forest 6-class classifier, a Random Forest binary classifier, and a Neural Network binary classifier. All models were evaluated using 5-fold cross-validation to ensure reliable performance estimates. Our primary focus was on predicting whether he would reach base (via hit or walk), with applications in sports betting and predictive sports analytics.

\subsection{Random Forest – 6-Class Classification}

The first model attempted to classify the outcome of each plate appearance into one of six classes: out, walk, single, double, home run, and others. The model achieved an overall accuracy of \textbf{67\%}, but performance was heavily skewed toward the majority class (outs).

\begin{itemize}
    \item Class 0 (out): Recall = 0.93, F1-score = 0.78
    \item Other classes: Near-zero recall and F1-scores
    \item Macro-averaged F1-score: 0.28
\end{itemize}

The confusion matrix in Figure~\ref{fig:rf_6_class_cm} shows the model’s strong bias toward predicting outs.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{rf_6_class_cm.png}
    \caption{Confusion matrix for Random Forest 6-class model}
    \label{fig:rf_6_class_cm}
\end{figure}

Due to class imbalance and poor generalization across all outcomes, this model was not suitable for fine-grained prediction.

\subsection{Random Forest – Binary Classification}

We reframed the task as a binary classification problem: predicting whether Ohtani would reach base (via hit or walk) or not. This improved the performance and interpretability of the model.

\begin{itemize}
    \item Accuracy: 70\%
    \item Class 0 (out): Precision = 0.72, Recall = 0.86
    \item Class 1 (reached base): Precision = 0.65, Recall = 0.45
    \item Macro-averaged F1-score: 0.66
    \item AUC: 0.70
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{rf_binary_cm.png}
    \caption{Confusion matrix for Random Forest binary model}
    \label{fig:rf_binary_cm}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{rf_binary_roc_curve.png}
    \caption{ROC curve for Random Forest binary model (AUC = 0.70)}
    \label{fig:rf_binary_roc}
\end{figure}

This version of the model was more balanced and effective for the task compared to the 6-class model.

\subsection{Neural Network – Binary Classification}

We also trained a feedforward neural network with early stopping, regularization, and AUC-based monitoring using the same binary target as above.

\begin{itemize}
    \item Accuracy: 66\%
    \item Class 0: Precision = 0.75, Recall = 0.67
    \item Class 1: Precision = 0.53, Recall = 0.63
    \item Macro-averaged F1-score: 0.64
    \item AUC: 0.72
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{nn_binary_cm.png}
    \caption{Confusion matrix for Neural Network binary model}
    \label{fig:nn_binary_cm}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{nn_roc_curve.png}
    \caption{ROC curve for Neural Network binary model (AUC = 0.72)}
    \label{fig:nn_roc_curve}
\end{figure}

The neural network showed balanced predictive power across both classes, slightly outperforming the Random Forest binary model in recall and AUC.

\subsection{Summary}

The binary neural network provided the most consistent performance in predicting successful outcomes, especially in recall and AUC. The binary random forest achieved the highest overall accuracy but missed many positive cases. The 6-class model, while interpretable, was limited by class imbalance and did not generalize well.


\section{Related Work}
Other works have shown how AI can help managers by using machine learning models to help make decisions during the game, as they can successfully predict the likely pitch of a player or the pitch that a hitter might be less likely to hit \cite{b7}. These stats are important to the game and can improve player performance, pitch selection, and game strategy. Other works also show constant improvements in the current Statcast system that tracks player data throughout a game using LiDAR scans of the entire stadium \cite{b8}. These improvements can provide more accurate data that increases our accuracy in future works. Previous research has also shown different results when including other statistics, such as relationships between the average launch angle, hang time, and horizontal landing angle of flyouts \cite{b6}. Creating more relationships between the hitting data and ways that a person could either be called out or be given a base hit might yield better results in future works. 


\section{Conclusions}
In this project, we explored the use of machine learning models to predict player hitting outcomes in Major League Baseball, with a focus on improving the accuracy of sports betting. We developed and evaluated multiple models by leveraging detailed datasets on player performance and batter-vs-pitcher matchups. Among the approaches tested, binary classification models proved to be the most effective, particularly the feedforward neural network, which demonstrated the best balance between precision and recall, and achieved the highest AUC score. The 6-class model struggled with class imbalance, however, reframing the problem as a binary classification and switching from a random forest model to a neural network model allowed for more practical and accurate predictions. These results suggest that machine learning has potential for enhancing predictive sports analytics, however, the widely available pre-game data might not be sufficient for truly accurate predictions. Further exploration into more granular or real-time data sources could improve predictive accuracy and lead to more robust betting models.

\section*{Supplementary Material}

Please find the link to our source code below:

\begin{itemize}
    \item \textbf{Source Code Repository:} \\
    \url{https://github.com/Aliuddink/CS-4210-Group-Project}

    \item \textbf{LaTeX Source Files:} \\
    \url{https://github.com/Aliuddink/CS-4210-Group-Project}
\end{itemize}

These include all Python scripts, datasets, Jupyter notebooks, and the full LaTeX report source.

% \subsection{Abbreviations and Acronyms}\label{AA}
% Define abbreviations and acronyms the first time they are used in the text, 
% even after they have been defined in the abstract. Abbreviations such as 
% IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
% abbreviations in the title or heads unless they are unavoidable.

% \subsection{Units}
% \begin{itemize}
% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
% \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
% \end{itemize}

% \subsection{Equations}
% Number equations consecutively. To make your 
% equations more compact, you may use the solidus (~/~), the exp function, or 
% appropriate exponents. Italicize Roman symbols for quantities and variables, 
% but not Greek symbols. Use a long dash rather than a hyphen for a minus 
% sign. Punctuate equations with commas or periods when they are part of a 
% sentence, as in:
% \begin{equation}
% a+b=\gamma\label{eq}
% \end{equation}

% Be sure that the 
% symbols in your equation have been defined before or immediately following 
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''

% \subsection{\LaTeX-Specific Advice}

% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.

% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.

% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.

% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files. 

% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3. 

% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.

% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.

% \subsection{Some Common Mistakes}\label{SCM}
% \begin{itemize}
% \item The word ``data'' is plural, not singular.
% \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
% \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
% \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
% \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
% \item Do not confuse ``imply'' and ``infer''.
% \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
% \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
% \end{itemize}
% An excellent style manual for science writers is \cite{b7}.

% \subsection{Authors and Affiliations}\label{AAA}
% \textbf{The class file is designed for, but not limited to, six authors.} A 
% minimum of one author is required for all conference articles. Author names 
% should be listed starting from left to right and then moving down to the 
% next line. This is the author sequence that will be used in future citations 
% and by indexing services. Names should not be listed in columns nor group by 
% affiliation. Please keep your affiliations as succinct as possible (for 
% example, do not differentiate among departments of the same organization).

% \subsection{Identify the Headings}\label{ITH}
% Headings, or heads, are organizational devices that guide the reader through 
% your paper. There are two types: component heads and text heads.

% Component heads identify the different components of your paper and are not 
% topically subordinate to each other. Examples include Acknowledgments and 
% References and, for these, the correct style to use is ``Heading 5''. Use 
% ``figure caption'' for your Figure captions, and ``table head'' for your 
% table title. Run-in heads, such as ``Abstract'', will require you to apply a 
% style (in this case, italic) in addition to the style provided by the drop 
% down menu to differentiate the head from the text.

% Text heads organize the topics on a relational, hierarchical basis. For 
% example, the paper title is the primary text head because all subsequent 
% material relates and elaborates on this one topic. If there are two or more 
% sub-topics, the next level head (uppercase Roman numerals) should be used 
% and, conversely, if there are not at least two sub-topics, then no subheads 
% should be introduced.

% \subsection{Figures and Tables}\label{FAT}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
% rather than symbols or abbreviations when writing Figure axis labels to 
% avoid confusing the reader. As an example, write the quantity 
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
% units in the label, present them within parentheses. Do not label axes only 
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
% quantities and units. For example, write ``Temperature (K)'', not 
% ``Temperature/K''.

% \section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without 
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
% acknowledgments in the unnumbered footnote on the first page.

\begin{thebibliography}{00}

\bibitem{b1} Baseball Savant. “Player Matchup - Baseball Savant.” \textit{MLB Statcast}, 2025. [Online]. Available: \url{https://baseballsavant.mlb.com}

\bibitem{b2} Baseball Savant. “Statcast Custom Leaderboards.” \textit{MLB Statcast}, 2024. [Online]. Available: \url{https://baseballsavant.mlb.com}

\bibitem{b3} J. D. Brooks, “
\textit{pybaseball: Baseball data made simple},” GitHub repository, 2024. [Online]. Available: 
\url{https://github.com/jldbc/pybaseball}

\bibitem{b4} Baseball Reference. “Baseball statistics and history,” 2024. [Online]. Available: \url{https://www.baseball-reference.com/}

\bibitem{b5} FanGraphs. “FanGraphs Baseball: Stats, analysis, and fantasy tools,” 2024. [Online]. Available: \url{https://-www.fangraphs.com/}

\bibitem{b6} Zhao W, Akella VS, Yang S, Luo X. Machine Learning in Baseball Analytics: Sabermetrics and Beyond. Information. 2025. 16(5):361. \url{https://doi.org/10.3390/info16050361}

\bibitem{b7} Central North Carolina Men's Senior Baseball League. "AI in Baseball," 2025. [Online]. Available: \url{https://www.cncmsbl.com/baseball-stuff/ai-in-baseball/}

\bibitem{b8} Chua, Sean Eugene. "The AI and ML Revolution in the MLB and NFL." 2024. [Online]. Available: \url{https://medium.com/demistify/the-ai-and-ml-revolution-in-the-mlb-and-nfl-8048b5519ec9}


\end{thebibliography}

\end{document}
