{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5038964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb84ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "FILE_PATH = \"ohtani_2024_pa_results.csv\" # Replace with your actual file path\n",
    "TARGET_COLUMN = 'target'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {FILE_PATH}\")\n",
    "    # Handle the error appropriately, e.g., exit or prompt user\n",
    "    exit()\n",
    "\n",
    "# --- Define Target Variable ---\n",
    "# Target: 1 if hit (single, double, triple, home_run) or walk, 0 otherwise\n",
    "positive_events = ['single', 'double', 'triple', 'home_run', 'walk']\n",
    "df[TARGET_COLUMN] = df['events'].apply(lambda x: 1 if isinstance(x, str) and x.lower() in positive_events else 0)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "# Create 'opponent_team' feature\n",
    "df['opponent_team'] = df.apply(lambda row: row['away_team'] if row['home_team'] == 'LAD' else row['home_team'], axis=1)\n",
    "\n",
    "# Select features (Dropping columns not used for training)\n",
    "# Note: Consider carefully which columns to drop. 'bb_type' might be useful if handled correctly.\n",
    "features_to_drop = ['events', 'launch_speed', 'launch_angle', 'hit_distance_sc', 'bb_type', 'home_team', 'away_team', TARGET_COLUMN]\n",
    "X = df.drop(columns=features_to_drop)\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "print(f\"Initial features: {X.columns.tolist()}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "# --- Handle Categorical Features ---\n",
    "# One-Hot Encode nominal features\n",
    "categorical_cols_ohe = ['pitch_name', 'opponent_team']\n",
    "X = pd.get_dummies(X, columns=categorical_cols_ohe, dummy_na=False, dtype=int) # dummy_na=False explicitly avoids creating NaN columns\n",
    "\n",
    "# Label Encode 'pitcher' (assuming high cardinality makes OHE less suitable)\n",
    "# Using try-except for robustness if 'pitcher' column is missing\n",
    "try:\n",
    "    le = LabelEncoder()\n",
    "    X['pitcher'] = le.fit_transform(X['pitcher'].astype(str)) # Convert to string to handle potential mixed types/NaNs before encoding\n",
    "    print(\"Label encoded 'pitcher'.\")\n",
    "except KeyError:\n",
    "    print(\"Warning: 'pitcher' column not found for label encoding.\")\n",
    "\n",
    "\n",
    "# --- Identify Numerical Features (After OHE) ---\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Numerical columns for imputation/scaling: {numerical_cols}\")\n",
    "\n",
    "# --- Handle Missing Numerical Values (Imputation with Mean) ---\n",
    "# Impute BEFORE splitting\n",
    "for col in numerical_cols:\n",
    "    if X[col].isnull().any():\n",
    "        mean_val = X[col].mean()\n",
    "        X[col] = X[col].fillna(mean_val)\n",
    "        print(f\"Imputed NaNs in '{col}' with mean ({mean_val:.2f}).\")\n",
    "\n",
    "# Verify no remaining NaNs (optional but recommended)\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"Warning: Remaining NaNs detected after imputation!\")\n",
    "    print(X.isnull().sum())\n",
    "else:\n",
    "    print(\"No NaNs remaining in features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/Test Split ---\n",
    "# Stratify ensures the proportion of target classes is similar in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=TEST_SIZE,\n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# --- Scale Numerical Features ---\n",
    "# Fit scaler ONLY on training data, then transform both train and test\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols]) # Use transform, not fit_transform, on test data\n",
    "\n",
    "print(\"Numerical features scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ef761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Model Architecture ---\n",
    "# Incorporating Batch Normalization and L2 Regularization\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "L2_REG = 0.001 # Regularization factor\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, kernel_regularizer=l2(L2_REG), input_shape=(INPUT_DIM,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5), # Dropout helps prevent overfitting\n",
    "\n",
    "    layers.Dense(32, kernel_regularizer=l2(L2_REG)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid') # Sigmoid for binary classification output\n",
    "])\n",
    "\n",
    "# --- Compile Model ---\n",
    "model.compile(optimizer='adam', # Adam is a common default choice\n",
    "              loss='binary_crossentropy', # Standard loss for binary classification\n",
    "              metrics=['accuracy', keras.metrics.AUC(name='auc')]) # Include AUC metric\n",
    "\n",
    "model.summary() # Print model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983711f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Configuration ---\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "EARLY_STOPPING_PATIENCE = 15 # Increased patience\n",
    "LR_REDUCTION_PATIENCE = 5\n",
    "\n",
    "# --- Callbacks ---\n",
    "# Early Stopping: Stop training if validation loss doesn't improve\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                             patience=EARLY_STOPPING_PATIENCE,\n",
    "                             restore_best_weights=True, # Keep the best model weights found\n",
    "                             verbose=1)\n",
    "\n",
    "# Reduce Learning Rate on Plateau: Reduce LR if validation loss stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2, # Reduce LR by a factor of 5\n",
    "                              patience=LR_REDUCTION_PATIENCE,\n",
    "                              min_lr=0.00001, # Minimum learning rate\n",
    "                              verbose=1)\n",
    "\n",
    "# --- Class Weights (Handle Imbalance) ---\n",
    "# Calculate weights to give more importance to the minority class during training\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"Calculated class weights: {class_weight_dict}\")\n",
    "\n",
    "\n",
    "# --- Train the Model ---\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr],\n",
    "                    class_weight=class_weight_dict, # Apply class weights\n",
    "                    verbose=1) # Set verbose=1 or 2 to see progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate on Test Set ---\n",
    "loss, accuracy, auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n--- Test Set Evaluation ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "\n",
    "# --- Predictions ---\n",
    "y_pred_prob = model.predict(X_test) # Get probabilities\n",
    "y_pred_binary = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions (using 0.5 threshold initially)\n",
    "\n",
    "# --- Classification Report & Confusion Matrix ---\n",
    "print(\"\\n--- Classification Report (Threshold=0.5) ---\")\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "print(\"\\n--- Confusion Matrix (Threshold=0.5) ---\")\n",
    "print(confusion_matrix(y_test, y_pred_binary))\n",
    "\n",
    "# --- ROC Curve ---\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ANN (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance') # Diagonal line\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Training History ---\n",
    "def plot_training_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    ax[0].plot(history.history['loss'], label='Train Loss')\n",
    "    ax[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax[0].set_title('Model Loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(loc='upper right')\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot Accuracy / AUC\n",
    "    metric_to_plot = 'auc' if 'auc' in history.history else 'accuracy'\n",
    "    val_metric_to_plot = 'val_auc' if 'val_auc' in history.history else 'val_accuracy'\n",
    "\n",
    "    ax[1].plot(history.history[metric_to_plot], label=f'Train {metric_to_plot.capitalize()}')\n",
    "    ax[1].plot(history.history[val_metric_to_plot], label=f'Validation {metric_to_plot.capitalize()}')\n",
    "    ax[1].set_title(f'Model {metric_to_plot.capitalize()}')\n",
    "    ax[1].set_ylabel(metric_to_plot.capitalize())\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(loc='lower right')\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Training History ---\")\n",
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
